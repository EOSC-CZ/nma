import sqlalchemy_utils.types
import sqlalchemy_utils
#
# This file is part of Invenio.
# Copyright (C) 2016-2018 CERN.
#
# Invenio is free software; you can redistribute it and/or modify it
# under the terms of the MIT License; see LICENSE file for more details.

"""Initial revision."""

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import mysql
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = 'nma_2'
down_revision = 'nma_1'
branch_labels = ()
depends_on = None


def upgrade():
    """Upgrade database."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('datasets_metadata_version',
    sa.Column('created', sa.DateTime().with_variant(mysql.DATETIME(fsp=6), 'mysql'), autoincrement=False, nullable=False),
    sa.Column('updated', sa.DateTime().with_variant(mysql.DATETIME(fsp=6), 'mysql'), autoincrement=False, nullable=False),
    sa.Column('id', sqlalchemy_utils.types.uuid.UUIDType(), autoincrement=False, nullable=False),
    sa.Column('json', sa.JSON().with_variant(sqlalchemy_utils.types.json.JSONType(), 'mysql').with_variant(postgresql.JSONB(none_as_null=True, astext_type=sa.Text()), 'postgresql').with_variant(sqlalchemy_utils.types.json.JSONType(), 'sqlite'), autoincrement=False, nullable=True),
    sa.Column('version_id', sa.Integer(), autoincrement=False, nullable=False),
    sa.Column('bucket_id', sqlalchemy_utils.types.uuid.UUIDType(), autoincrement=False, nullable=True),
    sa.Column('transaction_id', sa.BigInteger(), autoincrement=False, nullable=False),
    sa.Column('end_transaction_id', sa.BigInteger(), nullable=True),
    sa.Column('operation_type', sa.SmallInteger(), nullable=False),
    sa.PrimaryKeyConstraint('id', 'transaction_id', name=op.f('pk_datasets_metadata_version'))
    )
    op.create_index(op.f('ix_datasets_metadata_version_end_transaction_id'), 'datasets_metadata_version', ['end_transaction_id'], unique=False)
    op.create_index(op.f('ix_datasets_metadata_version_operation_type'), 'datasets_metadata_version', ['operation_type'], unique=False)
    op.create_index(op.f('ix_datasets_metadata_version_transaction_id'), 'datasets_metadata_version', ['transaction_id'], unique=False)
    op.create_table('datasets_metadata',
    sa.Column('created', sa.DateTime().with_variant(mysql.DATETIME(fsp=6), 'mysql'), nullable=False),
    sa.Column('updated', sa.DateTime().with_variant(mysql.DATETIME(fsp=6), 'mysql'), nullable=False),
    sa.Column('id', sqlalchemy_utils.types.uuid.UUIDType(), nullable=False),
    sa.Column('json', sa.JSON().with_variant(sqlalchemy_utils.types.json.JSONType(), 'mysql').with_variant(postgresql.JSONB(none_as_null=True, astext_type=sa.Text()), 'postgresql').with_variant(sqlalchemy_utils.types.json.JSONType(), 'sqlite'), nullable=True),
    sa.Column('version_id', sa.Integer(), nullable=False),
    sa.Column('bucket_id', sqlalchemy_utils.types.uuid.UUIDType(), nullable=True),
    sa.ForeignKeyConstraint(['bucket_id'], ['files_bucket.id'], name=op.f('fk_datasets_metadata_bucket_id_files_bucket')),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_datasets_metadata'))
    )
    op.create_table('datasets_file_metadata',
    sa.Column('created', sa.DateTime().with_variant(mysql.DATETIME(fsp=6), 'mysql'), nullable=False),
    sa.Column('updated', sa.DateTime().with_variant(mysql.DATETIME(fsp=6), 'mysql'), nullable=False),
    sa.Column('id', sqlalchemy_utils.types.uuid.UUIDType(), nullable=False),
    sa.Column('json', sa.JSON().with_variant(sqlalchemy_utils.types.json.JSONType(), 'mysql').with_variant(postgresql.JSONB(none_as_null=True, astext_type=sa.Text()), 'postgresql').with_variant(sqlalchemy_utils.types.json.JSONType(), 'sqlite'), nullable=True),
    sa.Column('version_id', sa.Integer(), nullable=False),
    sa.Column('key', sa.Text().with_variant(mysql.VARCHAR(length=255), 'mysql'), nullable=False),
    sa.Column('record_id', sqlalchemy_utils.types.uuid.UUIDType(), nullable=False),
    sa.Column('object_version_id', sqlalchemy_utils.types.uuid.UUIDType(), nullable=True),
    sa.ForeignKeyConstraint(['object_version_id'], ['files_object.version_id'], name=op.f('fk_datasets_file_metadata_object_version_id_files_object'), ondelete='RESTRICT'),
    sa.ForeignKeyConstraint(['record_id'], ['datasets_metadata.id'], name=op.f('fk_datasets_file_metadata_record_id_datasets_metadata'), ondelete='RESTRICT'),
    sa.PrimaryKeyConstraint('id', name=op.f('pk_datasets_file_metadata'))
    )
    op.create_index(op.f('ix_datasets_file_metadata_object_version_id'), 'datasets_file_metadata', ['object_version_id'], unique=False)
    op.create_index(op.f('ix_datasets_file_metadata_record_id'), 'datasets_file_metadata', ['record_id'], unique=False)
    op.create_index('uidx_datasets_file_metadata_record_id_key', 'datasets_file_metadata', ['record_id', 'key'], unique=True)
    op.drop_index('ix_uq_partial_files_object_is_head', table_name='files_object')
    # ### end Alembic commands ###


def downgrade():
    """Downgrade database."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_index('ix_uq_partial_files_object_is_head', 'files_object', ['bucket_id', 'key'], unique=False)
    op.drop_index('uidx_datasets_file_metadata_record_id_key', table_name='datasets_file_metadata')
    op.drop_index(op.f('ix_datasets_file_metadata_record_id'), table_name='datasets_file_metadata')
    op.drop_index(op.f('ix_datasets_file_metadata_object_version_id'), table_name='datasets_file_metadata')
    op.drop_table('datasets_file_metadata')
    op.drop_table('datasets_metadata')
    op.drop_index(op.f('ix_datasets_metadata_version_transaction_id'), table_name='datasets_metadata_version')
    op.drop_index(op.f('ix_datasets_metadata_version_operation_type'), table_name='datasets_metadata_version')
    op.drop_index(op.f('ix_datasets_metadata_version_end_transaction_id'), table_name='datasets_metadata_version')
    op.drop_table('datasets_metadata_version')
    # ### end Alembic commands ###
